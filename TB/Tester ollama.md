Avec ollama je vais tester différent [[LLM]] avec différent prompt pour voir lesquels sont les plus performants. 

## Les modèles que je veux tester 
- [ ] Chat-GPT 3.5
- [ ] Chat-GPT 4 (depuis bing ai)
- [ ] [[llama2]]
- [ ] [[mistral]]
- [ ] [[codellama]]
- [ ] [[dolphin-mixtral]]
- [ ] [[deepseek-coder]]
- [ ] [[wizardcoder]] (on peut tester pour voir, mais il dise que c'est surtout pour générer du code)